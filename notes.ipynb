{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bit is the amount of information required to choose between two equally probable alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose from *m* equally probably alternatives you need log*n* bits of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random variable *X* is a variable whose possible values are numerical outcomes of a random phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *source* generates *messages*. A *message* is an ordered sequence of symbols where each symbol corresponds to\n",
    "the value of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A message comprising symbols $s = (s_1, ..., s_k)$ is\n",
    "encoded by a function $x = g(s)$ into a sequence of codewords\n",
    "$x = (x_1, ... , x_n)$, where the number of symbols and codewords\n",
    "are not necessarily equal. These codewords are transmitted\n",
    "through a communication channel to produce outputs $y =\n",
    "(y_1, ... , y_n)$ which are decoded to recover the message $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of each symbol being generated by the source is defined by the probability distribution.  \n",
    "$p(S) = p(s_1), ... , p(s_\\alpha)$  \n",
    "where, by definition, the sum of p(s) values must add up to one,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shannon* is a unit of information. Due to unprobable events conveying more information than probable ones, it is said to be correlated to the measure of suprise or uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shannon information of a particular outcome is:  \n",
    "$h(x) = -log_2 \\ p(x) \\ bits$  \n",
    "where *h* is standard notation for Shannon information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information theory, the entropy of a random variable is the average level of \"information\", \"surprise\", or \"uncertainty\" inherent to the variable's possible outcomes.\n",
    "\n",
    "$ H(X) \\approx -\\sum_{x\\in X} p(x) \\ log \\ {p(x)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable with an entropy of $H(X)$ bits provides\n",
    "enough Shannon information to choose between $m = 2^{H(X)}$\n",
    "equally probable alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5, -0.5]\n",
      "1.0\n",
      "[-0.13680278410054497, -0.33219280948873625]\n",
      "0.4689955935892812\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def calcualte_entropy(*probabilties):\n",
    "  logarithms = map( lambda p : p * math.log2(p), probabilties)\n",
    "  print(list(logarithms))\n",
    "  return -sum(\n",
    "    map( lambda p : p * math.log(p,2), probabilties)\n",
    "  )\n",
    "\n",
    "print(calcualte_entropy(0.5, 0.5))\n",
    "print(calcualte_entropy(0.9, 0.1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
